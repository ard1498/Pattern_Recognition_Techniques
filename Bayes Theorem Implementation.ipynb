{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import model_selection as ms\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = good , 1 = very good , 2 = bad , 3 = poor\n",
    "xvals = [\n",
    "        ['Good', 'Accept'],\n",
    "        ['Bad','Accept'],\n",
    "        ['Very Good','Accept'],\n",
    "        ['Poor','Accept'],\n",
    "        ['Good','Reject'],\n",
    "        ['Very Good','Reject'],\n",
    "        ['Bad','Reject'],\n",
    "        ['Poor','Reject'], \n",
    "        ['Good','Neutral'],\n",
    "        ['Poor','Neutral'],\n",
    "        ['Bad','Neutral'],\n",
    "        ['Very Good','Neutral']\n",
    "    ]\n",
    "\n",
    "data = np.array([random.sample(xvals,1) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['Bad', 'Reject']],\n\n       [['Very Good', 'Reject']],\n\n       [['Poor', 'Reject']],\n\n       [['Good', 'Reject']],\n\n       [['Bad', 'Reject']],\n\n       [['Very Good', 'Accept']],\n\n       [['Bad', 'Neutral']],\n\n       [['Poor', 'Reject']],\n\n       [['Bad', 'Neutral']],\n\n       [['Very Good', 'Neutral']]], dtype='<U9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Bad', 'Very Good', 'Poor', ..., 'Good', 'Very Good',\n        'Very Good'],\n       ['Reject', 'Reject', 'Reject', ..., 'Accept', 'Reject', 'Neutral']],\n      dtype='<U9')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(1000,2).T\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = data[0],data[1]\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = ms.train_test_split(X,Y,test_size = 0.20 , random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.336, 0.347, 0.317)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priori_Accept = ((Y == 'Accept').sum()/1000)\n",
    "priori_Reject = ((Y == 'Reject').sum()/1000)\n",
    "priori_Neutral = ((Y == 'Neutral').sum()/1000)\n",
    "priori_Accept, priori_Reject, priori_Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bad', 'Good', 'Poor', 'Very Good'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'Good' : {'Accept' : 0 , 'Reject' : 0, 'Neutral' : 0},\n",
    "    'Very Good' : {'Accept' : 0 , 'Reject' : 0, 'Neutral' : 0},\n",
    "    'Poor' : {'Accept' : 0 , 'Reject' : 0, 'Neutral' : 0},\n",
    "    'Bad' : {'Accept' : 0 , 'Reject' : 0, 'Neutral' : 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(xtrain)):\n",
    "    dic[xtrain[i]][ytrain[i]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Good': {'Accept': 67, 'Reject': 66, 'Neutral': 79},\n",
       " 'Very Good': {'Accept': 67, 'Reject': 60, 'Neutral': 67},\n",
       " 'Poor': {'Accept': 64, 'Reject': 62, 'Neutral': 62},\n",
       " 'Bad': {'Accept': 69, 'Reject': 71, 'Neutral': 66}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(ytrain)\n",
    "counter['Reject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Good': {'Accept': 0.250936329588015,\n",
       "  'Reject': 0.2548262548262548,\n",
       "  'Neutral': 0.28832116788321166},\n",
       " 'Very Good': {'Accept': 0.250936329588015,\n",
       "  'Reject': 0.23166023166023167,\n",
       "  'Neutral': 0.24452554744525548},\n",
       " 'Poor': {'Accept': 0.2397003745318352,\n",
       "  'Reject': 0.23938223938223938,\n",
       "  'Neutral': 0.22627737226277372},\n",
       " 'Bad': {'Accept': 0.25842696629213485,\n",
       "  'Reject': 0.27413127413127414,\n",
       "  'Neutral': 0.24087591240875914}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(ytrain)\n",
    "counter['Reject']\n",
    "for i in dic:\n",
    "    dic[i]['Accept'] /= counter['Accept']\n",
    "    dic[i]['Reject'] /= counter['Reject']\n",
    "    dic[i]['Neutral'] /= counter['Neutral']\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.345"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ypred = []\n",
    "for i in range(len(xtest)):\n",
    "    probab_accept = dic[xtest[i]]['Accept'] * priori_Accept\n",
    "    probab_reject = dic[xtest[i]]['Reject'] * priori_Reject\n",
    "    probab_neutral = dic[xtest[i]]['Neutral'] * priori_Neutral\n",
    "    max_probab = max([probab_accept,probab_reject,probab_neutral])\n",
    "    if max_probab == probab_accept:\n",
    "        Ypred.append('Accept')\n",
    "    elif max_probab == probab_reject:\n",
    "        Ypred.append('Reject')\n",
    "    elif max_probab == probab_neutral:\n",
    "        Ypred.append('Neutral')\n",
    "        \n",
    "(Ypred == ytest).sum()/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Very Good', 'Neutral', 'Neutral')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest[0],ytest[0],Ypred[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
